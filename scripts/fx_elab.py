import os
import json
import time
import pandas as pd
import tiktoken
from datetime import datetime
from pathlib import Path
from scripts.dataframe import load_df, save_df, REPO_PATH, INFO_PATH, STRATEGY_PATH, PROMPT_PATH, init_prompt_df
from scripts.llm_router import call_llm

# ğŸ”§ ë¡œê¹… í•¨ìˆ˜
def log(message: str, log_file: Path):
    with log_file.open("a", encoding="utf-8") as f:
        f.write(f"[{datetime.now().strftime('%H:%M:%S')}] {message}\n")

def generate_tree_structure(base_path="."):
    tree_str = ""
    for root, dirs, files in os.walk(base_path):
        # ìˆ¨ê¹€ í´ë” ë° FILE ì œì™¸
        dirs[:] = [d for d in dirs if not d.startswith('.')]
        files = [f for f in files if not f.startswith('.')]

        for file in files:
            rel_path = os.path.relpath(os.path.join(root, file), base_path)
            tree_str += f"{rel_path}\n"

    return tree_str

# ğŸ“˜ README ì¶”ì¶œ í•¨ìˆ˜ (H1~H2 + ì²« ë¬¸ë‹¨)
def extract_readme_summary(readme_path):
    with open(readme_path, encoding="utf-8") as file:
        content = file.read()
    lines = content.split("\n")
    summary = []
    capture = False
    for line in lines:
        if line.startswith("# "):
            capture = True
        elif line.startswith("## ") and capture:
            break
        if capture:
            summary.append(line)
    if len(summary) <= 1:  # H1 ì—†ìœ¼ë©´ ì²« ë‹¨ë½
        summary = content.split("\n\n")[0]
    return "\n".join(summary).strip()

# ğŸ”‘ í‚¤ì›Œë“œ ê¸°ë°˜ ì½”ë“œ ì¤„ ì¶”ì¶œ
def extract_keywords_code(filepath):
    keywords = ("def ", "return ", "class ", "self", "@", "from ", "logger")
    with open(filepath, encoding="utf-8") as file:
        lines = file.readlines()
    return ''.join([line for line in lines if any(kw in line for kw in keywords)])

# âš™ï¸ main ì‹¤í–‰ í•¨ìˆ˜
def fx_elab_main():
    repo_df = load_df(REPO_PATH)
    info_df = load_df(INFO_PATH)
    strategy_df = load_df(STRATEGY_PATH)
    prompt_df = init_prompt_df()

    timestamp = datetime.now().strftime("%y%m%d_%H%M")
    log_dir = Path(f"logs/{timestamp}")
    log_dir.mkdir(parents=True, exist_ok=True)
    log_file = log_dir / "trigger.log"
    if not REPO_PATH.exists():
        from scripts.ext_info import extract_all_info
        extract_all_info()
    repo_df = load_df(REPO_PATH)
    root_path = Path(repo_df["root path"].iloc[0])
    tree_structure = generate_tree_structure(root_path)
    llm_cfg_path = Path("config/llm.json")
    llm_cfgs = json.loads(llm_cfg_path.read_text(encoding="utf-8"))
    fx_cfg = llm_cfgs["llm"]["fx_elab"]  # ğŸ’¡ ì—¬ê¸° í‚¤ ì´ë¦„ ì¤‘ìš”
    enc = tiktoken.encoding_for_model("llama4-maverick-instruct-basic")

    for idx, row in strategy_df.iterrows():
        file_name = row["FILE"]
        strategy = row["FILE STRATEGY"]
        file_path = root_path / '/'.join(info_df.loc[info_df["FILE"] == file_name, "FILE ìœ„ì¹˜"].iloc[0])
        
        # ë©”ì¸ ìŠ¤í¬ë¦½íŠ¸ FILE STRATEGY ì ìš©
        if strategy == "full_pass":
            with file_path.open("r", encoding="utf-8") as file:
                main_content = file.read()
        elif strategy == "mid_focus":
            main_content = extract_keywords_code(file_path)  # ê°„ëµí™”ëœ ë°©ì‹ (í•¨ìˆ˜ ì¤‘ì‹¬ ì¶”ì¶œ ê°€ëŠ¥)
        else:
            main_content = extract_keywords_code(file_path)
        
        # ì—°ê´€ ìŠ¤í¬ë¦½íŠ¸ ìš”ì•½
        related_files_info = []
        for related_file in row["ì—°ê´€ë„ ë†’ì€ FILE ë¦¬ìŠ¤íŠ¸"]:
            related_path = root_path / '/'.join(info_df.loc[info_df["FILE"] == related_file, "FILE ìœ„ì¹˜"].iloc[0])
            related_code = extract_keywords_code(related_path)
            recent_commit = info_df.loc[info_df["FILE"] == related_file, "5 LATEST COMMIT"].iloc[0][0]
            related_files_info.append(f"{related_file}:\n{related_code}\nìµœê·¼ ì»¤ë°‹: {recent_commit}\n")

        # ìµœê·¼ ì»¤ë°‹ ë©”ì‹œì§€ (ë©”ì¸ FILE)
        recent_commits_main = info_df.loc[info_df["FILE"] == file_name, "5 LATEST COMMIT"].iloc[0][:row["NUM OF EXTRACT FILE"]]
        
        # README ì²˜ë¦¬
        readme_strategy = row["readme strategy"]
        readme_content = ""
        readme_path = root_path / "README.md"
        if readme_strategy[0]:
            readme_content = extract_readme_summary(readme_path) if readme_strategy[1] == "summary" else readme_path.read_text(encoding="utf-8")

        # í”„ë¡¬í”„íŠ¸ ìƒì„±
        fx_in = f"""
ğŸ“Œ ìš”ì²­ ëª©ì :
ì•„ë˜ ìŠ¤í¬ë¦½íŠ¸ì˜ ì£¼ìš” ê¸°ëŠ¥ê³¼ ë¡œì§ì„ 300 tokens ë‚´ì™¸ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”.
ë ˆí¬ ì „ì²´ êµ¬ì¡°ì—ì„œì˜ ì—­í• ê³¼ ì—°ê³„ì„±ì„ í¬í•¨í•´ì£¼ì„¸ìš”.

ğŸ“Œ ë¶„ì„ FILE: {file_name}
ğŸ“ ê¸°ëŠ¥ ìœ í˜•: {row["ê¸°ëŠ¥ ìœ í˜•"]}
ğŸ“ IMPORTANCE: {row["IMPORTANCE"]}

ğŸ“ ë©”ì¸ ìŠ¤í¬ë¦½íŠ¸ ë‚´ìš©:
{main_content}

ğŸ“ ìµœê·¼ ì»¤ë°‹ ë©”ì‹œì§€ (ë©”ì¸ FILE):
{recent_commits_main}

ğŸ“ ê´€ë ¨ ìŠ¤í¬ë¦½íŠ¸ ìš”ì•½:
{"".join(related_files_info)}

ğŸ“ í´ë” êµ¬ì¡°:
{tree_structure}

ğŸ“ README ìš”ì•½:
{readme_content}
"""

        fx_in_path = log_dir / f"fx_in_{file_name}.txt"
        fx_in_path.write_text(fx_in, encoding="utf-8")

        token_in = len(enc.encode(fx_in))
        prompt_df.loc[len(prompt_df)] = {
            "IN/OUT": "ì…ë ¥", "VAR NAME": f"fx_in_{file_name}", "ì‚¬ìš© MODEL NAME": "llama4-maverick-instruct-basic",
            "meta(in)or purpose(out)": "FILE ë‚´ìš©, ê´€ë ¨ FILE, ì»¤ë°‹ ë©”ì‹œì§€, í´ë” êµ¬ì¡°, README",
            "SAVE PATH": str(fx_in_path), "ì—…ë¡œë“œ ì—¬ë¶€": False, "upload platform": "",
            "tokenê°’": token_in, "ë¹„ìš©($)": None, "ë¹„ìš©(krw)": None
        }
        log(f"âœ… í”„ë¡¬í”„íŠ¸ ìƒì„± ì™„ë£Œ: {fx_in_path}", log_file)

        # LLM í˜¸ì¶œ
        fx_out = call_llm(prompt=fx_in, llm_cfg=fx_cfg)#configë¶ˆëŸ¬ì˜¤ë„ë¡ ìˆ˜ì •

        fx_out_path = log_dir / f"fx_out_{file_name}.txt"
        fx_out_path.write_text(fx_out, encoding="utf-8")

        token_out = len(enc.encode(fx_out))
        prompt_df.loc[len(prompt_df)] = {
            "IN/OUT": "ì¶œë ¥", "VAR NAME": f"fx_out_{file_name}", "ì‚¬ìš© MODEL NAME": "llama4-maverick-instruct-basic",
            "meta(in)or purpose(out)": "commit msg ì‘ì„± ë¹½ê·¸ë¼ìš´ë“œ ì œì‘",
            "SAVE PATH": str(fx_out_path), "ì—…ë¡œë“œ ì—¬ë¶€": True, "upload platform": ["notify", "record"],
            "tokenê°’": token_out, "ë¹„ìš©($)": None, "ë¹„ìš©(krw)": None
        }
        log(f"âœ… LLM ì‘ë‹µ ì €ì¥ ì™„ë£Œ: {fx_out_path}", log_file)

        save_df(prompt_df, PROMPT_PATH)
        log("âœ… prompt_df ì €ì¥ ì™„ë£Œ", log_file)

        time.sleep(5)

fx_elab_main()
