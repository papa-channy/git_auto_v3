import os
import json
import time
import pandas as pd
import tiktoken
from datetime import datetime
from pathlib import Path
from dataframe import load_df, save_df, REPO_PATH, INFO_PATH, STRATEGY_PATH, PROMPT_PATH, init_prompt_df
from llm_router import call_llm

# ğŸ”§ ë¡œê¹… í•¨ìˆ˜
def log(message: str, log_file: Path):
    with log_file.open("a", encoding="utf-8") as f:
        f.write(f"[{datetime.now().strftime('%H:%M:%S')}] {message}\n")

# ğŸ—ƒï¸ í´ë” êµ¬ì¡° íŠ¸ë¦¬ ë¬¸ìì—´ ìƒì„± (ìˆ¨ê¹€ íŒŒì¼ ì œì™¸)
def generate_tree_structure(base_path):
    tree_str = ""
    for root, dirs, files in os.walk(base_path):
        dirs[:] = [d for d in dirs if not d.startswith('.')]
        files = [f for f in files if not f.startswith('.')]
        depth = root[len(str(base_path)):].count(os.sep)
        indent = 'â”‚   ' * depth + 'â”œâ”€â”€ '
        tree_str += f"{indent}{Path(root).name}/\n"
        subindent = 'â”‚   ' * (depth + 1) + 'â”œâ”€â”€ '
        for f in files:
            tree_str += f"{subindent}{f}\n"
    return tree_str

# ğŸ“˜ README ì¶”ì¶œ í•¨ìˆ˜ (H1~H2 + ì²« ë¬¸ë‹¨)
def extract_readme_summary(readme_path):
    with open(readme_path, encoding="utf-8") as file:
        content = file.read()
    lines = content.split("\n")
    summary = []
    capture = False
    for line in lines:
        if line.startswith("# "):
            capture = True
        elif line.startswith("## ") and capture:
            break
        if capture:
            summary.append(line)
    if len(summary) <= 1:  # H1 ì—†ìœ¼ë©´ ì²« ë‹¨ë½
        summary = content.split("\n\n")[0]
    return "\n".join(summary).strip()

# ğŸ”‘ í‚¤ì›Œë“œ ê¸°ë°˜ ì½”ë“œ ì¤„ ì¶”ì¶œ
def extract_keywords_code(filepath):
    keywords = ("def ", "return ", "class ", "self", "@", "from ", "logger")
    with open(filepath, encoding="utf-8") as file:
        lines = file.readlines()
    return ''.join([line for line in lines if any(kw in line for kw in keywords)])

# âš™ï¸ main ì‹¤í–‰ í•¨ìˆ˜
def fx_elab_main():
    repo_df = load_df(REPO_PATH)
    info_df = load_df(INFO_PATH)
    strategy_df = load_df(STRATEGY_PATH)
    prompt_df = init_prompt_df()

    timestamp = datetime.now().strftime("%y%m%d_%H%M")
    log_dir = Path(f"logs/{timestamp}")
    log_dir.mkdir(parents=True, exist_ok=True)
    log_file = log_dir / "trigger.log"
    
    root_path = Path(repo_df["ë£¨íŠ¸ path"].iloc[0])
    tree_structure = generate_tree_structure(root_path)

    enc = tiktoken.encoding_for_model("llama4-maverick-instruct-basic")

    for idx, row in strategy_df.iterrows():
        file_name = row["íŒŒì¼"]
        strategy = row["ë¶„ì„ ì „ëµ"]
        file_path = root_path / '/'.join(info_df.loc[info_df["íŒŒì¼"] == file_name, "íŒŒì¼ ìœ„ì¹˜"].iloc[0])
        
        # ë©”ì¸ ìŠ¤í¬ë¦½íŠ¸ ë¶„ì„ ì „ëµ ì ìš©
        if strategy == "full_pass":
            with file_path.open("r", encoding="utf-8") as file:
                main_content = file.read()
        elif strategy == "mid_focus":
            main_content = extract_keywords_code(file_path)  # ê°„ëµí™”ëœ ë°©ì‹ (í•¨ìˆ˜ ì¤‘ì‹¬ ì¶”ì¶œ ê°€ëŠ¥)
        else:
            main_content = extract_keywords_code(file_path)
        
        # ì—°ê´€ ìŠ¤í¬ë¦½íŠ¸ ìš”ì•½
        related_files_info = []
        for related_file in row["ì—°ê´€ë„ ë†’ì€ íŒŒì¼ ë¦¬ìŠ¤íŠ¸"]:
            related_path = root_path / '/'.join(info_df.loc[info_df["íŒŒì¼"] == related_file, "íŒŒì¼ ìœ„ì¹˜"].iloc[0])
            related_code = extract_keywords_code(related_path)
            recent_commit = info_df.loc[info_df["íŒŒì¼"] == related_file, "ìµœê·¼ ì»¤ë°‹ ë©”ì‹œì§€ 5ê°œ"].iloc[0][0]
            related_files_info.append(f"{related_file}:\n{related_code}\nìµœê·¼ ì»¤ë°‹: {recent_commit}\n")

        # ìµœê·¼ ì»¤ë°‹ ë©”ì‹œì§€ (ë©”ì¸ íŒŒì¼)
        recent_commits_main = info_df.loc[info_df["íŒŒì¼"] == file_name, "ìµœê·¼ ì»¤ë°‹ ë©”ì‹œì§€ 5ê°œ"].iloc[0][:row["ì¶”ì¶œí•  ì»¤ë°‹ ë©”ì‹œì§€ ê°œìˆ˜"]]
        
        # README ì²˜ë¦¬
        readme_strategy = row["readme ì „ëµ"]
        readme_content = ""
        readme_path = root_path / "README.md"
        if readme_strategy[0]:
            readme_content = extract_readme_summary(readme_path) if readme_strategy[1] == "summary" else readme_path.read_text(encoding="utf-8")

        # í”„ë¡¬í”„íŠ¸ ìƒì„±
        fx_in = f"""
ğŸ“Œ ìš”ì²­ ëª©ì :
ì•„ë˜ ìŠ¤í¬ë¦½íŠ¸ì˜ ì£¼ìš” ê¸°ëŠ¥ê³¼ ë¡œì§ì„ 300 tokens ë‚´ì™¸ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”.
ë ˆí¬ ì „ì²´ êµ¬ì¡°ì—ì„œì˜ ì—­í• ê³¼ ì—°ê³„ì„±ì„ í¬í•¨í•´ì£¼ì„¸ìš”.

ğŸ“Œ ë¶„ì„ íŒŒì¼: {file_name}
ğŸ“ ê¸°ëŠ¥ ìœ í˜•: {row["ê¸°ëŠ¥ ìœ í˜•"]}
ğŸ“ ì¤‘ìš”ë„ ì ìˆ˜: {row["ì¤‘ìš”ë„ ì ìˆ˜"]}

ğŸ“ ë©”ì¸ ìŠ¤í¬ë¦½íŠ¸ ë‚´ìš©:
{main_content}

ğŸ“ ìµœê·¼ ì»¤ë°‹ ë©”ì‹œì§€ (ë©”ì¸ íŒŒì¼):
{recent_commits_main}

ğŸ“ ê´€ë ¨ ìŠ¤í¬ë¦½íŠ¸ ìš”ì•½:
{"".join(related_files_info)}

ğŸ“ í´ë” êµ¬ì¡°:
{tree_structure}

ğŸ“ README ìš”ì•½:
{readme_content}
"""

        fx_in_path = log_dir / f"fx_in_{file_name}.txt"
        fx_in_path.write_text(fx_in, encoding="utf-8")

        token_in = len(enc.encode(fx_in))
        prompt_df.loc[len(prompt_df)] = {
            "ì…ë ¥/ì¶œë ¥": "ì…ë ¥", "ë³€ìˆ˜ëª…": f"fx_in_{file_name}", "ì‚¬ìš© ëª¨ë¸": "llama4-maverick-instruct-basic",
            "ì‚¬ìš©í•œ ì •ë³´(ì…ë ¥)orëª©ì (ì¶œë ¥)": "íŒŒì¼ ë‚´ìš©, ê´€ë ¨ íŒŒì¼, ì»¤ë°‹ ë©”ì‹œì§€, í´ë” êµ¬ì¡°, README",
            "ì €ì¥ ìœ„ì¹˜": str(fx_in_path), "ì—…ë¡œë“œ ì—¬ë¶€": False, "upload platform": "",
            "tokenê°’": token_in, "ë¹„ìš©($)": None, "ë¹„ìš©(krw)": None
        }
        log(f"âœ… í”„ë¡¬í”„íŠ¸ ìƒì„± ì™„ë£Œ: {fx_in_path}", log_file)

        # LLM í˜¸ì¶œ
        fx_out = call_llm(prompt=fx_in, model="llama4-maverick-instruct-basic")#configë¶ˆëŸ¬ì˜¤ë„ë¡ ìˆ˜ì •

        fx_out_path = log_dir / f"fx_out_{file_name}.txt"
        fx_out_path.write_text(fx_out, encoding="utf-8")

        token_out = len(enc.encode(fx_out))
        prompt_df.loc[len(prompt_df)] = {
            "ì…ë ¥/ì¶œë ¥": "ì¶œë ¥", "ë³€ìˆ˜ëª…": f"fx_out_{file_name}", "ì‚¬ìš© ëª¨ë¸": "llama4-maverick-instruct-basic",
            "ì‚¬ìš©í•œ ì •ë³´(ì…ë ¥)orëª©ì (ì¶œë ¥)": "commit msg ì‘ì„± ë¹½ê·¸ë¼ìš´ë“œ ì œì‘",
            "ì €ì¥ ìœ„ì¹˜": str(fx_out_path), "ì—…ë¡œë“œ ì—¬ë¶€": True, "upload platform": ["notify", "record"],
            "tokenê°’": token_out, "ë¹„ìš©($)": None, "ë¹„ìš©(krw)": None
        }
        log(f"âœ… LLM ì‘ë‹µ ì €ì¥ ì™„ë£Œ: {fx_out_path}", log_file)

        save_df(prompt_df, PROMPT_PATH)
        log("âœ… prompt_df ì €ì¥ ì™„ë£Œ", log_file)

        time.sleep(5)

fx_elab_main()
