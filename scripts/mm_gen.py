from datetime import datetime
import os
import json
import pandas as pd
import tiktoken
from dataframe import (
    load_df, save_df,
    REPO_PATH, INFO_PATH, STRATEGY_PATH, PROMPT_PATH,
    init_prompt_df
)
from llm_router import call_llm


def split_chunks(lst, n):
    avg = len(lst) / float(n)
    out = []
    last = 0.0
    while last < len(lst):
        out.append(lst[int(last):int(last + avg)])
        last += avg
    return out


def log(message: str, log_file: str):
    with open(log_file, "a", encoding="utf-8") as f:
        f.write(f"[{datetime.now().strftime('%H:%M:%S')}] {message}\n")


def build_strategy_pp(repo_df, info_df, strategy_df, file_chunk):
    files_info = info_df[info_df["íŒŒì¼"].isin(file_chunk)].to_dict(orient="records")
    readme_map = {row["íŒŒì¼"]: row["readme ì „ëµ"] for _, row in strategy_df.iterrows()}
    readme_summary = {f["íŒŒì¼"]: readme_map[f["íŒŒì¼"]] for f in file_chunk}
    recent_commits = info_df[info_df["íŒŒì¼"].isin(file_chunk)]["ìµœê·¼ ì»¤ë°‹ ë©”ì‹œì§€ 5ê°œ"].to_dict()

    prompt = f"""
ğŸ“Œ ìš”ì²­ ëª©ì :
ê° ë³€ê²½ íŒŒì¼ì— ëŒ€í•´ ë‹¤ìŒ ì •ë³´ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ì˜ˆì¸¡í•´ì£¼ì„¸ìš”:
- ì‘ì„± ë””í…Œì¼ ë“±ê¸‰ (int, 1~5)
- ê¸°ëŠ¥ ìœ í˜• (str)
- ì¤‘ìš”ë„ ì ìˆ˜ (int, 0~10)
- ì—°ê´€ë„ ë†’ì€ íŒŒì¼ ë¦¬ìŠ¤íŠ¸ (list[str], ìµœëŒ€ 3ê°œ)

ğŸ“Œ ì¶œë ¥ JSON ì˜ˆì‹œ:
[
  {{
    "íŒŒì¼": "ext_info.py",
    "ì‘ì„± ë””í…Œì¼ ë“±ê¸‰": 4,
    "ê¸°ëŠ¥ ìœ í˜•": "Git ë©”íƒ€ ìˆ˜ì§‘",
    "ì¤‘ìš”ë„ ì ìˆ˜": 9,
    "ì—°ê´€ë„ ë†’ì€ íŒŒì¼ ë¦¬ìŠ¤íŠ¸": ["dataframe.py", "llm_router.py", "gen_msg.py"]
  }},
  ...
]

ğŸ“Œ ì¶œë ¥ í˜•ì‹ (í˜•ì‹ ì—„ìˆ˜):
[
  {{
    "íŒŒì¼": str,
    "ì‘ì„± ë””í…Œì¼ ë“±ê¸‰": int,
    "ê¸°ëŠ¥ ìœ í˜•": str,
    "ì¤‘ìš”ë„ ì ìˆ˜": int,
    "ì—°ê´€ë„ ë†’ì€ íŒŒì¼ ë¦¬ìŠ¤íŠ¸": list[str]
  }},
  ...
]

ğŸ“ ì‘ì„± ë””í…Œì¼ ë“±ê¸‰ ì°¸ê³  ì •ë³´:
- ì£¼ ë¸Œëœì¹˜: {repo_df["ì£¼ ë¸Œëœì¹˜"].iloc[0]}
- í˜„ì¬ ë¸Œëœì¹˜: {repo_df["í˜„ì¬ ë¸Œëœì¹˜"].iloc[0]}
- ë¸Œëœì¹˜ ëª©ë¡: {repo_df["ë¸Œëœì¹˜ list"].iloc[0]}
- ë³€ê²½ ìš”ì•½ í†µê³„: {repo_df["ë³€ê²½ ìš”ì•½ í†µê³„"].iloc[0]}

ğŸ“ ë ˆí¬ ì „ì²´ í´ë” êµ¬ì¡°:
{repo_df["ë£¨íŠ¸ path"].iloc[0]}

ğŸ“ README ë‚´ìš© ìš”ì•½ (íŒŒì¼ë³„):
{json.dumps(readme_summary, ensure_ascii=False)}

ğŸ“ ìµœê·¼ ì»¤ë°‹ ë©”ì‹œì§€ 5ê°œ (íŒŒì¼ë³„):
{json.dumps(recent_commits, ensure_ascii=False)}

ğŸ“ ê° íŒŒì¼ ì •ë³´:
{json.dumps(files_info, ensure_ascii=False)}
"""

    return prompt

# ğŸ¯ ì „ì²´ ì‹¤í–‰ í•¨ìˆ˜
def mm_gen_main():
    repo_df = load_df(REPO_PATH)
    info_df = load_df(INFO_PATH)
    strategy_df = load_df(STRATEGY_PATH)
    prompt_df = init_prompt_df()

    file_list = strategy_df["íŒŒì¼"].tolist()
    n = len(file_list)

    if n > 60:
        raise SystemExit("âš ï¸ ë³€ê²½ íŒŒì¼ ìˆ˜ê°€ 60ê°œ ì´ˆê³¼ â†’ ì‘ì—… ì¢…ë£Œ")

    chunks = (
        split_chunks(file_list, 3) if n > 50 else
        split_chunks(file_list, 2) if n > 20 else
        [file_list]
    )

    all_results = []
    enc = tiktoken.encoding_for_model("gpt-4")

    timestamp = datetime.now().strftime("%y%m%d_%H%M")
    log_dir = f"logs/{timestamp}"
    os.makedirs(log_dir, exist_ok=True)
    log_file = f"{log_dir}/trigger.log"

    for chunk in chunks:
        st_pp_in = build_strategy_pp(repo_df, info_df, strategy_df, chunk)

        in_path = f"{log_dir}/st_pp_in.txt"
        with open(in_path, "w", encoding="utf-8") as f:
            f.write(st_pp_in)
        log(f"âœ… í”„ë¡¬í”„íŠ¸ ìƒì„± ì™„ë£Œ: {in_path}", log_file)

        token_in = len(enc.encode(st_pp_in))
        prompt_df.loc[len(prompt_df)] = {
            "ì…ë ¥/ì¶œë ¥": "ì…ë ¥",
            "ë³€ìˆ˜ëª…": "st_pp_in",
            "ì‚¬ìš© ëª¨ë¸": "gpt-4o",
            "ì‚¬ìš©í•œ ì •ë³´(ì…ë ¥)orëª©ì (ì¶œë ¥)": "í´ë” êµ¬ì¡°, README ì „ëµ, ë³€ê²½ íŒŒì¼ ëª©ë¡, ìµœê·¼ ì»¤ë°‹ ë©”ì‹œì§€ 5ê°œ, ë¸Œëœì¹˜ ì •ë³´, ë³€ê²½ ìš”ì•½ í†µê³„, íŒŒì¼ ìœ í˜•, íŒŒì¼ ìœ„ì¹˜",
            "ì €ì¥ ìœ„ì¹˜": in_path,
            "ì—…ë¡œë“œ ì—¬ë¶€": False,
            "upload platform": "",
            "tokenê°’": token_in,
            "ë¹„ìš©($)": None,
            "ë¹„ìš©(krw)": None
        }

        response = call_llm(prompt=st_pp_in, model="gpt-4o")
        out_path = f"{log_dir}/st_pp_out.txt"
        with open(out_path, "w", encoding="utf-8") as f:
            f.write(response)
        log(f"âœ… GPT-4o ì‘ë‹µ ì €ì¥ ì™„ë£Œ: {out_path}", log_file)

        token_out = len(enc.encode(response))
        prompt_df.loc[len(prompt_df)] = {
            "ì…ë ¥/ì¶œë ¥": "ì¶œë ¥",
            "ë³€ìˆ˜ëª…": "st_pp_out",
            "ì‚¬ìš© ëª¨ë¸": "gpt-4o",
            "ì‚¬ìš©í•œ ì •ë³´(ì…ë ¥)orëª©ì (ì¶œë ¥)": "strategy_df_value",
            "ì €ì¥ ìœ„ì¹˜": out_path,
            "ì—…ë¡œë“œ ì—¬ë¶€": False,
            "upload platform": "",
            "tokenê°’": token_out,
            "ë¹„ìš©($)": None,
            "ë¹„ìš©(krw)": None
        }

        parsed = json.loads(response)
        log("âœ… íŒŒì‹± ì„±ê³µ ë° strategy_df ë°˜ì˜ ì¤‘...", log_file)
        all_results.extend(parsed)

    for row in all_results:
        idx = strategy_df[strategy_df["íŒŒì¼"] == row["íŒŒì¼"]].index[0]
        strategy_df.at[idx, "ì‘ì„± ë””í…Œì¼ ë“±ê¸‰"] = row["ì‘ì„± ë””í…Œì¼ ë“±ê¸‰"]
        strategy_df.at[idx, "ê¸°ëŠ¥ ìœ í˜•"] = row["ê¸°ëŠ¥ ìœ í˜•"]
        strategy_df.at[idx, "ì¤‘ìš”ë„ ì ìˆ˜"] = row["ì¤‘ìš”ë„ ì ìˆ˜"]
        strategy_df.at[idx, "ì—°ê´€ë„ ë†’ì€ íŒŒì¼ ë¦¬ìŠ¤íŠ¸"] = row["ì—°ê´€ë„ ë†’ì€ íŒŒì¼ ë¦¬ìŠ¤íŠ¸"]

    save_df(strategy_df, STRATEGY_PATH)
    save_df(prompt_df, PROMPT_PATH)
    log("âœ… ì „ëµ ê²°ê³¼ ë° í”„ë¡¬í”„íŠ¸ ì¶”ì  ì €ì¥ ì™„ë£Œ", log_file)