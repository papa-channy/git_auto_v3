diff --git a/scripts/gen_msg.py b/scripts/gen_msg.py
index 333a18e..196f48e 100644
--- a/scripts/gen_msg.py
+++ b/scripts/gen_msg.py
@@ -1,80 +1,101 @@
-from datetime import datetime
-import os
-import json
-import time
-import tiktoken
 from pathlib import Path
-from scripts.dataframe import load_df, save_df, REPO_PATH, INFO_PATH, STRATEGY_PATH, PROMPT_PATH, init_prompt_df
-from scripts.llm_router import call_llm
-
-def log(message: str, log_file: Path):
-    with log_file.open("a", encoding="utf-8") as f:
-        f.write(f"[{datetime.now().strftime('%H:%M:%S')}] {message}\n")
+from scripts.dataframe import load_df
+from scripts.ext_info import to_safe_filename
+from utils.cfg import cfg
+from scripts.llm_mng import LLMManager
+
+def select_prompt_template(length: int, importance: int) -> str:
+    if length >= 500 or importance >= 8:
+        return "internal_detail"
+    elif length >= 200:
+        return "internal"
+    else:
+        return "solo_detail"
 
 def gen_msg_main():
-    repo_df = load_df(REPO_PATH)
-    info_df = load_df(INFO_PATH)
-    strategy_df = load_df(STRATEGY_PATH)
-    prompt_df = init_prompt_df()
-
-    # ì„¤ì • ë¡œë”©
-    style = json.loads(Path("config/style.json").read_text(encoding="utf-8"))
-    llm_cfgs = json.loads(Path("config/llm.json").read_text(encoding="utf-8"))
-    commit_style = style["style"]["commit_final"]
-    commit_lang = style["language"]["commit"]
-    llm_cfg = llm_cfgs["llm"]["commit_final"]
-
-    # ë¡œê·¸ ì„¤ì •
-    timestamp = datetime.now().strftime("%y%m%d_%H%M")
-    log_dir = Path(f"logs/{timestamp}")
-    log_dir.mkdir(parents=True, exist_ok=True)
-    log_file = log_dir / "trigger.log"
-    root_path = Path(repo_df["root path"].iloc[0])
-    enc = tiktoken.encoding_for_model(llm_cfg["model"][0])
-
-    # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ë¯¸ë¦¬ ë¡œë”©
-    prompt_template = Path(f"prompt/{commit_lang}/{commit_style}.txt").read_text(encoding="utf-8")
-
-    for row in strategy_df.itertuples():
-        filename = row.FILE
-        file_path = root_path / "/".join(info_df[info_df["FILE"] == filename]["FILE ìœ„ì¹˜"].iloc[0])
-        if not file_path.exists():
-            log(f"âŒ FILE ì—†ìŒ: {file_path}", log_file)
-            continue
+    timestamp = cfg.get_timestamp()
+    paths = cfg.get_results_path(timestamp)
+    log_file = cfg.init_log_file(timestamp)
+
+    repo_df = load_df(paths["repo"])
+    info_df = load_df(paths["info"])
+    strategy_df = load_df(paths["strategy"])
+
+    # í´ë” êµ¬ì¡° ì •ì œ ë°©ì‹ìœ¼ë¡œ êµì²´
+    root_path = Path(str(repo_df["Root path"].iloc[0]))
+    folder_lines, file_lines = cfg.build_llm_file_structure(root_path)
+    tree_txt = "\n".join(folder_lines + file_lines)
 
-        # ğŸ“„ ìŠ¤í¬ë¦½íŠ¸ í…ìŠ¤íŠ¸ ì¶”ì¶œ
-        if row.ë¶„ì„_ì „ëµ == "full_pass":
-            script_txt = file_path.read_text(encoding="utf-8")
-        else:
-            lines = file_path.read_text(encoding="utf-8").splitlines()
-            keywords = ["def ", "return ", "class ", "self", "@", "from ", "logger"]
-            script_txt = "\n".join([line for line in lines if any(k in line for k in keywords)])
-
-        # ğŸ§  ê¸°ëŠ¥ ìš”ì•½ í…ìŠ¤íŠ¸ ë¶ˆëŸ¬ì˜¤ê¸°
-        fx_path = log_dir / f"fx_out_{filename}.txt"
-        if not fx_path.exists():
-            log(f"âš ï¸ fx_out FILE ì—†ìŒ: {fx_path}", log_file)
+    prompts, tags, safe_files = [], [], []
+
+    lang = "ko"
+    for _, row in strategy_df.iterrows():
+        if row["Importance"] <= 3:
             continue
-        fx_summary = fx_path.read_text(encoding="utf-8")
 
-        # ğŸ§¾ diff í…ìŠ¤íŠ¸ ë¶ˆëŸ¬ì˜¤ê¸°
-        diff_var = info_df[info_df["FILE"] == filename]["diff var name"].iloc[0]
-        diff_path = Path(f"results/diff_final/{diff_var}.txt")
-        if not diff_path.exists():
-            log(f"âš ï¸ diff í…ìŠ¤íŠ¸ ì—†ìŒ: {diff_path}", log_file)
+        file = row["File"]
+        safe_file = to_safe_filename(file)
+        safe_files.append(safe_file)
+
+        info_row = info_df[info_df["file"] == file]
+        if info_row.empty:
+            cfg.log(f"[gen_msg] âš ï¸ {file} ê²½ë¡œ ì •ë³´ ì—†ìŒ", log_file)
             continue
-        diff_txt = diff_path.read_text(encoding="utf-8")
 
-        # ğŸ“Œ ìµœê·¼ ì»¤ë°‹ ë©”ì‹œì§€
-        commit_msgs = info_df[info_df["FILE"] == filename]["5 LATEST COMMIT"].iloc[0]
-        recent_commit = "\n".join(commit_msgs[:row.ì¶”ì¶œí• _ì»¤ë°‹_ë©”ì‹œì§€_ê°œìˆ˜])
+        file_path = Path(info_row["path"].iloc[0]) / safe_file
+
+        fx_path = paths["explain_out"].with_name(f"out_{safe_file}.txt")
+        diff_path = paths["diff"] / f"diff_{Path(safe_file).stem}.txt"
+
+
+        try:
+            fx_summary = fx_path.read_text(encoding="utf-8")
+        except Exception:
+            fx_summary = ""
+            cfg.log(f"[gen_msg] âŒ {file} ê¸°ëŠ¥ ìš”ì•½ íŒŒì¼ ì½ê¸° ì‹¤íŒ¨", log_file)
+
+        try:
+            diff_txt = diff_path.read_text(encoding="utf-8")
+        except Exception:
+            diff_txt = ""
+            cfg.log(f"[gen_msg] âŒ {file} diff íŒŒì¼ ì½ê¸° ì‹¤íŒ¨", log_file)
+
+        strategy = row["File strategy"]
+        try:
+            script_txt = (
+                file_path.read_text(encoding="utf-8")
+                if strategy == "full_pass"
+                else "\n".join([
+                    l for l in file_path.read_text(encoding="utf-8").splitlines()
+                    if any(k in l for k in ["def ", "return ", "class ", "self", "@", "from ", "logger"])
+                ])
+            )
+        except Exception:
+            script_txt = ""
+            cfg.log(f"[gen_msg] âŒ {file} ì½”ë“œ ì½ê¸° ì‹¤íŒ¨", log_file)
+
+        try:
+            commit_list = info_row["5 latest commit"].iloc[0]
+            commit_summary = "\n".join(commit_list[:row["Num of extract file"]])
+        except Exception:
+            commit_summary = ""
+            cfg.log(f"[gen_msg] âš ï¸ {file} ì»¤ë°‹ ìš”ì•½ ì¶”ì¶œ ì‹¤íŒ¨", log_file)
+
+        length = row["Recommended length"] or 300
+        importance = row["Importance"] or 5
+        style = select_prompt_template(length, importance)
+        template_path = Path(f"prompt/{lang}/{style}.txt")
+        if not template_path.exists():
+            cfg.log(f"[gen_msg] âŒ í…œí”Œë¦¿ ì—†ìŒ: {template_path}", log_file)
+            continue
 
-        # ğŸ—‚ï¸ í´ë” êµ¬ì¡°
-        tree_txt_path = Path("results/context/tree.txt")
-        tree_txt = tree_txt_path.read_text(encoding="utf-8") if tree_txt_path.exists() else ""
+        try:
+            base_prompt = template_path.read_text(encoding="utf-8")
+        except Exception:
+            cfg.log(f"[gen_msg] âŒ í…œí”Œë¦¿ ì½ê¸° ì‹¤íŒ¨: {template_path}", log_file)
+            continue
 
-        # ğŸ§¾ í”„ë¡¬í”„íŠ¸ ìƒì„±
-        full_prompt = prompt_template.replace("{change}", f"""
+        full_prompt = base_prompt.replace("{change}", f"""
 ğŸ“˜ ê¸°ëŠ¥ ìš”ì•½:
 {fx_summary}
 
@@ -85,43 +106,21 @@ def gen_msg_main():
 {script_txt}
 
 ğŸ“Œ ìµœê·¼ ì»¤ë°‹ ë©”ì‹œì§€:
-{recent_commit}
+{commit_summary}
 
 ğŸ§¾ ë³€ê²½ ì‚¬í•­(diff):
 {diff_txt}
 """).strip()
 
-        # ğŸ” í”„ë¡¬í”„íŠ¸ ì €ì¥ ë° ì¶”ì 
-        prompt_file = log_dir / f"commit_in_{filename}.txt"
-        prompt_file.write_text(full_prompt, encoding="utf-8")
-        token_in = len(enc.encode(full_prompt))
-        prompt_df.loc[len(prompt_df)] = {
-            "IN/OUT": "ì…ë ¥", "VAR NAME": f"commit_in_{filename}",
-            "ì‚¬ìš© MODEL NAME": llm_cfg["model"][0],
-            "meta(in)or purpose(out)": "ê¸°ëŠ¥ ìš”ì•½, í´ë” êµ¬ì¡°, ìµœê·¼ ì»¤ë°‹ ë©”ì‹œì§€, ë³€ê²½ ìŠ¤í¬ë¦½íŠ¸, diff",
-            "SAVE PATH": str(prompt_file), "ì—…ë¡œë“œ ì—¬ë¶€": False,
-            "upload platform": "", "tokenê°’": token_in,
-            "ë¹„ìš©($)": None, "ë¹„ìš©(krw)": None
-        }
-        log(f"âœ… ì»¤ë°‹ í”„ë¡¬í”„íŠ¸ ìƒì„± ì™„ë£Œ: {prompt_file}", log_file)
-
-        # LLM í˜¸ì¶œ
-        response = call_llm(prompt=full_prompt, llm_cfg=llm_cfg, log=lambda m: log(m, log_file))
-        result_file = log_dir / f"commit_out_{filename}.txt"
-        result_file.write_text(response, encoding="utf-8")
-        token_out = len(enc.encode(response))
-
-        prompt_df.loc[len(prompt_df)] = {
-            "IN/OUT": "ì¶œë ¥", "VAR NAME": f"commit_out_{filename}",
-            "ì‚¬ìš© MODEL NAME": llm_cfg["model"][0],
-            "meta(in)or purpose(out)": "ìµœì¢… ì»¤ë°‹ ë©”ì‹œì§€ ìƒì„±",
-            "SAVE PATH": str(result_file), "ì—…ë¡œë“œ ì—¬ë¶€": True,
-            "upload platform": ["notify", "record"],
-            "tokenê°’": token_out, "ë¹„ìš©($)": None, "ë¹„ìš©(krw)": None
-        }
-        log(f"âœ… ì»¤ë°‹ ë©”ì‹œì§€ ìƒì„± ì™„ë£Œ: {result_file}", log_file)
-
-        save_df(prompt_df, PROMPT_PATH)
-        time.sleep(5)
-
-gen_msg_main()
+        prompts.append(full_prompt)
+        tags.append(file)
+
+    with LLMManager("mk_msg", repo_df, df_for_call=strategy_df) as llm:
+        results = llm.call_all(prompts, tags)
+        for safe_file, result in zip(safe_files, results):
+            if result.startswith("[ERROR]"):
+                cfg.log(f"[gen_msg] âŒ {safe_file} í˜¸ì¶œ ì‹¤íŒ¨: {result}", log_file)
+                continue
+            result_path = paths["mk_msg_out"].with_name(f"out_{safe_file}.txt")
+            result_path.write_text(result, encoding="utf-8")
+        llm.save_all()