diff --git a/scripts/fx_elab.py b/scripts/fx_elab.py
index 7152955..27c3f4d 100644
--- a/scripts/fx_elab.py
+++ b/scripts/fx_elab.py
@@ -1,166 +1,154 @@
-import os
-import json
-import time
-import pandas as pd
-import tiktoken
-from datetime import datetime
 from pathlib import Path
-from scripts.dataframe import load_df, save_df, REPO_PATH, INFO_PATH, STRATEGY_PATH, PROMPT_PATH, init_prompt_df
-from scripts.llm_router import call_llm
-
-# ğŸ”§ ë¡œê¹… í•¨ìˆ˜
-def log(message: str, log_file: Path):
-    with log_file.open("a", encoding="utf-8") as f:
-        f.write(f"[{datetime.now().strftime('%H:%M:%S')}] {message}\n")
-
-def generate_tree_structure(base_path="."):
-    tree_str = ""
-    for root, dirs, files in os.walk(base_path):
-        # ìˆ¨ê¹€ í´ë” ë° FILE ì œì™¸
-        dirs[:] = [d for d in dirs if not d.startswith('.')]
-        files = [f for f in files if not f.startswith('.')]
-
-        for file in files:
-            rel_path = os.path.relpath(os.path.join(root, file), base_path)
-            tree_str += f"{rel_path}\n"
-
-    return tree_str
-
-# ğŸ“˜ README ì¶”ì¶œ í•¨ìˆ˜ (H1~H2 + ì²« ë¬¸ë‹¨)
-def extract_readme_summary(readme_path):
-    with open(readme_path, encoding="utf-8") as file:
-        content = file.read()
-    lines = content.split("\n")
-    summary = []
-    capture = False
-    for line in lines:
-        if line.startswith("# "):
-            capture = True
-        elif line.startswith("## ") and capture:
-            break
-        if capture:
-            summary.append(line)
-    if len(summary) <= 1:  # H1 ì—†ìœ¼ë©´ ì²« ë‹¨ë½
-        summary = content.split("\n\n")[0]
-    return "\n".join(summary).strip()
-
-# ğŸ”‘ í‚¤ì›Œë“œ ê¸°ë°˜ ì½”ë“œ ì¤„ ì¶”ì¶œ
-def extract_keywords_code(filepath):
+from scripts.dataframe import load_df, save_df
+from utils.cfg import cfg
+from scripts.llm_mng import LLMManager
+from scripts.ext_info import to_safe_filename
+import pandas as pd
+
+def extract_keywords_code(filepath: Path) -> str:
     keywords = ("def ", "return ", "class ", "self", "@", "from ", "logger")
-    with open(filepath, encoding="utf-8") as file:
-        lines = file.readlines()
-    return ''.join([line for line in lines if any(kw in line for kw in keywords)])
+    try:
+        lines = filepath.read_text(encoding="utf-8").splitlines()
+        return "\n".join([line for line in lines if any(kw in line for kw in keywords)])
+    except Exception:
+        return ""
+
+def extract_readme_summary(readme_path: Path) -> str:
+    try:
+        content = readme_path.read_text(encoding="utf-8")
+        lines = content.split("\n")
+        summary, capture = [], False
+        for line in lines:
+            if line.startswith("# "): capture = True
+            elif line.startswith("## ") and capture: break
+            if capture: summary.append(line)
+        return "\n".join(summary).strip() if summary else content.split("\n\n")[0]
+    except Exception:
+        return ""
 
-# âš™ï¸ main ì‹¤í–‰ í•¨ìˆ˜
 def fx_elab_main():
-    repo_df = load_df(REPO_PATH)
-    info_df = load_df(INFO_PATH)
-    strategy_df = load_df(STRATEGY_PATH)
-    prompt_df = init_prompt_df()
-
-    timestamp = datetime.now().strftime("%y%m%d_%H%M")
-    log_dir = Path(f"logs/{timestamp}")
-    log_dir.mkdir(parents=True, exist_ok=True)
-    log_file = log_dir / "trigger.log"
-    if not REPO_PATH.exists():
-        from scripts.ext_info import extract_all_info
-        extract_all_info()
-    repo_df = load_df(REPO_PATH)
-    root_path = Path(repo_df["root path"].iloc[0])
-    tree_structure = generate_tree_structure(root_path)
-    llm_cfg_path = Path("config/llm.json")
-    llm_cfgs = json.loads(llm_cfg_path.read_text(encoding="utf-8"))
-    fx_cfg = llm_cfgs["llm"]["fx_elab"]  # ğŸ’¡ ì—¬ê¸° í‚¤ ì´ë¦„ ì¤‘ìš”
-    enc = tiktoken.encoding_for_model("llama4-maverick-instruct-basic")
-
-    for idx, row in strategy_df.iterrows():
-        file_name = row["FILE"]
-        strategy = row["FILE STRATEGY"]
-        file_path = root_path / '/'.join(info_df.loc[info_df["FILE"] == file_name, "FILE ìœ„ì¹˜"].iloc[0])
-        
-        # ë©”ì¸ ìŠ¤í¬ë¦½íŠ¸ FILE STRATEGY ì ìš©
-        if strategy == "full_pass":
-            with file_path.open("r", encoding="utf-8") as file:
-                main_content = file.read()
-        elif strategy == "mid_focus":
-            main_content = extract_keywords_code(file_path)  # ê°„ëµí™”ëœ ë°©ì‹ (í•¨ìˆ˜ ì¤‘ì‹¬ ì¶”ì¶œ ê°€ëŠ¥)
+    timestamp = cfg.get_timestamp()
+    paths = cfg.get_results_path(timestamp)
+    log_file = cfg.init_log_file(timestamp)
+
+    repo_df = load_df(paths["repo"])
+    info_df = load_df(paths["info"])
+    strategy_df = load_df(paths["strategy"])
+
+    root_path = Path(repo_df["Root path"].iloc[0])
+    readme_path = root_path / "README.md"
+    folder_lines, file_lines = cfg.build_llm_file_structure(root_path)
+    tree_structure = "\n".join(folder_lines + file_lines)
+
+    prompts, tags, meta_rows = [], [], []
+
+    for _, row in strategy_df.iterrows():
+        file = row["File"]
+        id_ = row["id"]
+        name4save = row["name4save"]
+        save_path = row["save_path"]
+        fx_in_path = Path(save_path[1])
+        fx_out_path = Path(save_path[2])
+
+        info_row = info_df[info_df["file"] == file]
+        if info_row.empty:
+            cfg.log(f"[fx_elab] âš ï¸ {file} ê²½ë¡œ ì •ë³´ ì—†ìŒ", log_file)
+            continue
+
+        file_path = Path(info_row["path"].iloc[0]) / to_safe_filename(file)
+        strategy = row["File strategy"]
+
+        try:
+            main_content = (
+                file_path.read_text(encoding="utf-8")
+                if strategy == "full_pass"
+                else extract_keywords_code(file_path)
+            )
+        except Exception:
+            main_content = ""
+            cfg.log(f"[fx_elab] âŒ {file} íŒŒì¼ ì½ê¸° ì‹¤íŒ¨", log_file)
+
+        related_info = []
+        for related in row.get("Most Related Files", []):
+            match = info_df[info_df["file"] == related]
+            if match.empty:
+                cfg.log(f"[fx_elab] âš ï¸ ê´€ë ¨ íŒŒì¼ ì—†ìŒ: {related}", log_file)
+                continue
+            r_path = Path(match["path"].iloc[0]) / to_safe_filename(related)
+            r_code = extract_keywords_code(r_path)
+            r_commit = match["5 latest commit"].iloc[0][:1]
+            related_info.append(f"{related}:\n{r_code}\nìµœê·¼ ì»¤ë°‹: {r_commit[0] if r_commit else ''}\n")
+        if not related_info:
+            related_info.append("ê´€ë ¨ íŒŒì¼ ì—†ìŒ")
+
+        try:
+            commit_lines = "\n".join(
+                info_row["5 latest commit"].iloc[0][:row["Num of extract file"]]
+            )
+        except Exception:
+            commit_lines = ""
+            cfg.log(f"[fx_elab] âš ï¸ ì»¤ë°‹ ì •ë³´ ëˆ„ë½: {file}", log_file)
+
+        readme_flag = row.get("Readme strategy", [False, "x"])
+        if readme_flag[0]:
+            try:
+                readme_content = (
+                    extract_readme_summary(readme_path)
+                    if readme_flag[1] == "summary"
+                    else readme_path.read_text(encoding="utf-8")
+                )
+            except Exception:
+                readme_content = ""
         else:
-            main_content = extract_keywords_code(file_path)
-        
-        # ì—°ê´€ ìŠ¤í¬ë¦½íŠ¸ ìš”ì•½
-        related_files_info = []
-        for related_file in row["ì—°ê´€ë„ ë†’ì€ FILE ë¦¬ìŠ¤íŠ¸"]:
-            related_path = root_path / '/'.join(info_df.loc[info_df["FILE"] == related_file, "FILE ìœ„ì¹˜"].iloc[0])
-            related_code = extract_keywords_code(related_path)
-            recent_commit = info_df.loc[info_df["FILE"] == related_file, "5 LATEST COMMIT"].iloc[0][0]
-            related_files_info.append(f"{related_file}:\n{related_code}\nìµœê·¼ ì»¤ë°‹: {recent_commit}\n")
-
-        # ìµœê·¼ ì»¤ë°‹ ë©”ì‹œì§€ (ë©”ì¸ FILE)
-        recent_commits_main = info_df.loc[info_df["FILE"] == file_name, "5 LATEST COMMIT"].iloc[0][:row["NUM OF EXTRACT FILE"]]
-        
-        # README ì²˜ë¦¬
-        readme_strategy = row["readme strategy"]
-        readme_content = ""
-        readme_path = root_path / "README.md"
-        if readme_strategy[0]:
-            readme_content = extract_readme_summary(readme_path) if readme_strategy[1] == "summary" else readme_path.read_text(encoding="utf-8")
-
-        # í”„ë¡¬í”„íŠ¸ ìƒì„±
-        fx_in = f"""
+            readme_content = ""
+
+        prompt = f"""
 ğŸ“Œ ìš”ì²­ ëª©ì :
 ì•„ë˜ ìŠ¤í¬ë¦½íŠ¸ì˜ ì£¼ìš” ê¸°ëŠ¥ê³¼ ë¡œì§ì„ 300 tokens ë‚´ì™¸ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”.
 ë ˆí¬ ì „ì²´ êµ¬ì¡°ì—ì„œì˜ ì—­í• ê³¼ ì—°ê³„ì„±ì„ í¬í•¨í•´ì£¼ì„¸ìš”.
 
-ğŸ“Œ ë¶„ì„ FILE: {file_name}
-ğŸ“ ê¸°ëŠ¥ ìœ í˜•: {row["ê¸°ëŠ¥ ìœ í˜•"]}
-ğŸ“ IMPORTANCE: {row["IMPORTANCE"]}
+ğŸ“ ë¶„ì„ FILE: {file}
+ğŸ“ ê¸°ëŠ¥ ìœ í˜•: {row['Component Type']}
+ğŸ“ ì¤‘ìš”ë„: {row['Importance']}
 
 ğŸ“ ë©”ì¸ ìŠ¤í¬ë¦½íŠ¸ ë‚´ìš©:
 {main_content}
 
-ğŸ“ ìµœê·¼ ì»¤ë°‹ ë©”ì‹œì§€ (ë©”ì¸ FILE):
-{recent_commits_main}
+ğŸ“ ìµœê·¼ ì»¤ë°‹ ë©”ì‹œì§€:
+{commit_lines}
 
 ğŸ“ ê´€ë ¨ ìŠ¤í¬ë¦½íŠ¸ ìš”ì•½:
-{"".join(related_files_info)}
+{"".join(related_info)}
 
 ğŸ“ í´ë” êµ¬ì¡°:
 {tree_structure}
 
 ğŸ“ README ìš”ì•½:
 {readme_content}
-"""
-
-        fx_in_path = log_dir / f"fx_in_{file_name}.txt"
-        fx_in_path.write_text(fx_in, encoding="utf-8")
-
-        token_in = len(enc.encode(fx_in))
-        prompt_df.loc[len(prompt_df)] = {
-            "IN/OUT": "ì…ë ¥", "VAR NAME": f"fx_in_{file_name}", "ì‚¬ìš© MODEL NAME": "llama4-maverick-instruct-basic",
-            "meta(in)or purpose(out)": "FILE ë‚´ìš©, ê´€ë ¨ FILE, ì»¤ë°‹ ë©”ì‹œì§€, í´ë” êµ¬ì¡°, README",
-            "SAVE PATH": str(fx_in_path), "ì—…ë¡œë“œ ì—¬ë¶€": False, "upload platform": "",
-            "tokenê°’": token_in, "ë¹„ìš©($)": None, "ë¹„ìš©(krw)": None
-        }
-        log(f"âœ… í”„ë¡¬í”„íŠ¸ ìƒì„± ì™„ë£Œ: {fx_in_path}", log_file)
+ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
+""".strip()
 
-        # LLM í˜¸ì¶œ
-        fx_out = call_llm(prompt=fx_in, llm_cfg=fx_cfg)#configë¶ˆëŸ¬ì˜¤ë„ë¡ ìˆ˜ì •
+        fx_in_path.parent.mkdir(parents=True, exist_ok=True)
+        fx_in_path.write_text(prompt, encoding="utf-8")
 
-        fx_out_path = log_dir / f"fx_out_{file_name}.txt"
-        fx_out_path.write_text(fx_out, encoding="utf-8")
+        prompts.append(prompt)
+        tags.append(id_)
+        meta_rows.append({
+            "id": id_,
+            "name4save": name4save,
+            "save_path": [str(fx_in_path), str(fx_out_path)]
+        })
 
-        token_out = len(enc.encode(fx_out))
-        prompt_df.loc[len(prompt_df)] = {
-            "IN/OUT": "ì¶œë ¥", "VAR NAME": f"fx_out_{file_name}", "ì‚¬ìš© MODEL NAME": "llama4-maverick-instruct-basic",
-            "meta(in)or purpose(out)": "commit msg ì‘ì„± ë¹½ê·¸ë¼ìš´ë“œ ì œì‘",
-            "SAVE PATH": str(fx_out_path), "ì—…ë¡œë“œ ì—¬ë¶€": True, "upload platform": ["notify", "record"],
-            "tokenê°’": token_out, "ë¹„ìš©($)": None, "ë¹„ìš©(krw)": None
-        }
-        log(f"âœ… LLM ì‘ë‹µ ì €ì¥ ì™„ë£Œ: {fx_out_path}", log_file)
+    if not prompts:
+        cfg.log("[fx_elab] âŒ ìƒì„±ëœ í”„ë¡¬í”„íŠ¸ ì—†ìŒ", log_file)
+        return
 
-        save_df(prompt_df, PROMPT_PATH)
-        log("âœ… prompt_df ì €ì¥ ì™„ë£Œ", log_file)
+    df_for_call = pd.DataFrame(meta_rows)
 
-        time.sleep(5)
+    with LLMManager("explain", repo_df, df_for_call=df_for_call) as llm:
+        results = llm.call_all(prompts, tags)
+        for result, row in zip(results, meta_rows):
+            fx_out_path = Path(row["save_path"][1])
+            fx_out_path.write_text(result, encoding="utf-8")
 
-fx_elab_main()
+        llm.save_all()