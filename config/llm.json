{   "llm": 
    {
        "stprompt": 
        {
            "provider": ["openai"],
            "model": ["gpt-4o"],
            "temperature": 0.5,
            "top_p": 0.8,
            "top_k": 40,
            "max_tokens": 8000
        },
        "fx_pp": 
        {
            "provider": ["openai"],
            "model": ["gpt-4o"],
            "temperature": 0.8,
            "top_p": 0.9,
            "top_k": 80,
            "max_tokens": 4096
        },
        "commit": 
        {
            "provider": ["fireworks"],
            "model": ["llama4-maverick-instruct-basic"],
            "temperature": 0.7,
            "top_p": 0.7,
            "top_k": 40,
            "max_tokens": 4096
        }
    }
}
